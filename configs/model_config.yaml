# Common configuration across all models and tasks
common:
  deterministic: true
  mixed_precision: false
  save_frequency: 5
  gradient_clipping: 1.0
  seed: 42
  device: "cuda:0"
  transforms:
    normalization:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
    validation:
      resize: 256
      center_crop: 224

# Model architecture feature dimensions
architectures:
  resnet18:
    output_features: 512
  gigapath:
    output_features: 1536
  convnext_large:
    output_features: 1536
  swin_v2_b:
    output_features: 1024
  densenet121:
    output_features: 1024
  densenet169:
    output_features: 1664

# Inflammation task configurations
inflammation:
  # ResNet18 configuration - Updated based on Höfling's thesis (Section 8.2.1)
  resnet18:
    architecture:
      name: resnet18
      pretrained: true
      feature_extraction: false
    batch_size: 128        # "With a learning rate of 0.001 and a batch size of 128"
    dropout_rate: 0.0      # "Due to the already higher validation loss than the training loss, the author decided not to test other methods like dropout"
    epochs: 25             # "It was trained for 25 epochs"
    optimizer:
      name: SGD            # SGD was used, with momentum 0.9
      learning_rate: 0.001 # "With a learning rate of 0.001"
      momentum: 0.9        # Standard SGD momentum
      weight_decay: 0.0    # Not mentioned in thesis
    pos_weight: 0.7
    scheduler:
      enabled: false       # "A learning rate scheduler was not employed"
    early_stopping:
      enabled: true
      patience: 15         # "Early stopping enforced after 15 epochs"
    transforms:
      training:
        random_resized_crop:
          size: 224
          scale: [0.8, 1.0]
        random_horizontal_flip: false  # Not specified as used in the optimal combination
        random_vertical_flip: false    # Not specified as used in the optimal combination
        color_jitter:
          enabled: false               # "Color jitter augmentation seems to have a negative impact"
        random_rotation:               # "Random rotation and gaussian blur had a positive effect"
          enabled: true
          degrees: 180
        random_blur:                   # "The most effective combination, consisting of random blur and random rotations"
          enabled: true
          kernel_size: 3
        random_affine:
          enabled: false               # Not specified as used in the optimal combination
          
  # DenseNet121 configuration
  densenet121:
    architecture:
      name: densenet121
      pretrained: true
      feature_extraction: false
    batch_size: 32
    dropout_rate: 0.2
    epochs: 30
    optimizer:
      name: AdamW
      learning_rate: 1e-4
      weight_decay: 1e-5
    pos_weight: 0.7
    scheduler:
      enabled: true
      name: CosineAnnealingLR
      T_max: 30
    early_stopping:
      enabled: true
      patience: 10
    transforms:
      training:
        random_resized_crop:
          size: 224
          scale: [0.8, 1.0]
        random_horizontal_flip: true
        random_vertical_flip: true
        color_jitter:
          enabled: false
        random_rotation:
          enabled: true
          degrees: 180
        random_blur:
          enabled: true
          kernel_size: 3
        random_affine:
          enabled: false
          
  # DenseNet169 configuration
  densenet169:
    architecture:
      name: densenet169
      pretrained: true
      feature_extraction: false
    batch_size: 24
    dropout_rate: 0.3
    epochs: 30
    optimizer:
      name: AdamW
      learning_rate: 5e-5
      weight_decay: 1e-5
    pos_weight: 0.7
    scheduler:
      enabled: true
      name: CosineAnnealingLR
      T_max: 30
    early_stopping:
      enabled: true
      patience: 10
    transforms:
      training:
        random_resized_crop:
          size: 224
          scale: [0.8, 1.0]
        random_horizontal_flip: true
        random_vertical_flip: true
        color_jitter:
          enabled: false
        random_rotation:
          enabled: true
          degrees: 180
        random_blur:
          enabled: true
          kernel_size: 3
        random_affine:
          enabled: false

  # Other models remain unchanged
  gigapath:
    architecture:
      name: gigapath
      pretrained: true
      feature_extraction: true
    batch_size: 32
    dropout_rate: 0.3
    epochs: 50
    optimizer:
      name: AdamW
      learning_rate: 5e-4
      weight_decay: 1e-5
    pos_weight: 0.7
    scheduler:
      enabled: true
      name: CosineAnnealingLR
      T_max: 50
    transforms:
      training:
        random_resized_crop:
          size: 224
          scale: [0.8, 1.0]
        random_horizontal_flip: true
        random_vertical_flip: true
        color_jitter:
          enabled: false
        random_rotation: 
          enabled: true
          degrees: 180
        random_blur:
          enabled: true
          kernel_size: 3
        random_affine:
          enabled: false

  convnext_large:
    architecture:
      name: convnext_large
      pretrained: true
      feature_extraction: false
    batch_size: 32
    dropout_rate: 0.4
    epochs: 50
    optimizer:
      name: AdamW
      learning_rate: 3e-5
      weight_decay: 8e-6
    pos_weight: 0.7
    scheduler:
      enabled: true
      name: CosineAnnealingLR
      T_max: 50
    transforms:
      training:
        random_resized_crop:
          size: 224
          scale: [0.7, 1.0]
        random_horizontal_flip: true
        random_vertical_flip: true
        color_jitter:
          enabled: false
        random_rotation: 
          enabled: true
          degrees: 180
        random_blur:
          enabled: true
          kernel_size: 3
        random_affine:
          enabled: false

  swin_v2_b:
    architecture:
      name: swin_v2_b
      pretrained: true
      feature_extraction: false
    batch_size: 32
    dropout_rate: 0.35
    epochs: 50
    optimizer:
      name: AdamW
      learning_rate: 5e-5
      weight_decay: 1e-5
    pos_weight: 0.7
    scheduler:
      enabled: true
      name: CosineAnnealingLR
      T_max: 50
    transforms:
      training:
        random_resized_crop:
          size: 224
          scale: [0.8, 1.0]
        random_horizontal_flip: true
        random_vertical_flip: true
        color_jitter:
          enabled: false
        random_rotation: 
          enabled: true
          degrees: 180
        random_blur:
          enabled: true
          kernel_size: 3
        random_affine:
          enabled: false

# Tissue task configurations
tissue:
  # ResNet18 configuration - Updated based on Höfling's thesis (Section 8.2.2)
  resnet18:
    architecture:
      name: resnet18
      pretrained: true
      feature_extraction: false
    batch_size: 64            # "Which had a batch size of 64"
    dropout_rate: 0.0         # "Implementing dropout... did not further reduce the validation loss"
    epochs: 60                # "Each model underwent training for a total of 60 epochs"
    optimizer:
      name: SGD                # "SGD with a momentum value set to 0.9 was chosen as optimizer"
      learning_rate: 0.001     # "With a learning rate of 0.001 and a batch size of 64"
      momentum: 0.9            # "SGD with a momentum value set to 0.9"
      weight_decay: 0.0        # "Implementing... weight decay did not further reduce the validation loss"
    pos_weight: 0.8
    scheduler:
      enabled: false           # "Implementing... learning rate schedulers... did not further reduce the validation loss"
    early_stopping:
      enabled: true 
      patience: 15             # "Early stopping implemented after 15 epochs"
    transforms:
      training:
        random_resized_crop:
          size: 224
          scale: [0.8, 1.0]
        random_horizontal_flip: true   # "The most effective combination, consisting of random flips and rotation"
        random_vertical_flip: true     # Assuming both horizontal and vertical flips
        color_jitter:
          enabled: false                # "Color jitter... had a negative impact on the models performance"
        random_rotation:                # "The most effective combination, consisting of random flips and rotation"
          enabled: true
          degrees: 180
        random_blur:
          enabled: false                # Not part of the optimal combination for tissue
        random_affine:
          enabled: false                # Not mentioned for tissue

  # Other models remain unchanged
  gigapath:
    architecture:
      name: gigapath
      pretrained: true
      feature_extraction: true
    batch_size: 32
    dropout_rate: 0.3
    epochs: 50
    optimizer:
      name: AdamW
      learning_rate: 5e-4
      weight_decay: 1e-5
    pos_weight: 0.8
    scheduler:
      enabled: true
      name: CosineAnnealingLR
      T_max: 50
    transforms:
      training:
        random_resized_crop:
          size: 224
          scale: [0.8, 1.0]
        random_horizontal_flip: true
        random_vertical_flip: true
        color_jitter:
          enabled: false
        random_rotation: 
          enabled: true
          degrees: 180
        random_blur:
          enabled: false
        random_affine:
          enabled: false

  convnext_large:
    architecture:
      name: convnext_large
      pretrained: true
      feature_extraction: false
    batch_size: 64
    dropout_rate: 0.08032651841331968
    epochs: 50
    optimizer:
      name: AdamW
      learning_rate: 0.0007554560492975331
      weight_decay: 1.7518424648360045e-05
    pos_weight: 0.693469462948584
    scheduler:
      enabled: true
      name: CosineAnnealingLR
      T_max: 50
    transforms:
      training:
        random_resized_crop:
          size: 224
          scale: [0.8, 1.0]
        random_horizontal_flip: true
        random_vertical_flip: true
        color_jitter:
          enabled: false
        random_rotation: 
          enabled: true
          degrees: 180
        random_blur:
          enabled: false
        random_affine:
          enabled: false

  swin_v2_b:
    architecture:
      name: swin_v2_b
      pretrained: true
      feature_extraction: false
    batch_size: 32
    dropout_rate: 0.35
    epochs: 50
    optimizer:
      name: AdamW
      learning_rate: 5e-5
      weight_decay: 1e-5
    pos_weight: 0.8
    scheduler:
      enabled: true
      name: CosineAnnealingLR
      T_max: 50
    transforms:
      training:
        random_resized_crop:
          size: 224
          scale: [0.8, 1.0]
        random_horizontal_flip: true
        random_vertical_flip: true
        color_jitter:
          enabled: false
        random_rotation: 
          enabled: true
          degrees: 180
        random_blur:
          enabled: false
        random_affine:
          enabled: false